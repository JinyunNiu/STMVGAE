{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T08:36:17.853194500Z",
     "start_time": "2024-04-17T08:36:14.412868600Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd                                                \n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import sys\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "from adj import graph\n",
    "from train import train_model\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tiling image: 100%|██████████ [ time left: 00:00 ]\n",
      "Extract image feature:   0%|           [ time left: ? ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 11\u001B[0m\n\u001B[0;32m      6\u001B[0m k \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m  \u001B[38;5;66;03m#the number of spatial domain \u001B[39;00m\n\u001B[0;32m      7\u001B[0m ann_data \u001B[38;5;241m=\u001B[39m sc\u001B[38;5;241m.\u001B[39mread_visium(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(DLPFC_dir, section_id),\n\u001B[0;32m      8\u001B[0m                           count_file\u001B[38;5;241m=\u001B[39msection_id \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_filtered_feature_bc_matrix.h5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 11\u001B[0m train \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDLPFC_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43minput_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43msection_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msection_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43mcnnType\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mResNet50\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mactivate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mRelu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mdistType\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdistType\u001B[49m\u001B[43m,\u001B[49m\u001B[43mrad_cutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m250\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mk_cutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m12\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m ann_data \u001B[38;5;241m=\u001B[39m train\u001B[38;5;241m.\u001B[39mfit(clusterType\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMclust\u001B[39m\u001B[38;5;124m'\u001B[39m,cluster_n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25\u001B[39m)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# load groud truth\u001B[39;00m\n",
      "File \u001B[1;32mD:\\njy\\Project_AI_stRNA\\Code\\STMVGAE\\train.py:48\u001B[0m, in \u001B[0;36mtrain_model.__init__\u001B[1;34m(self, input_dim, path, section_id, cnnType, activate, distType, rad_cutoff, k_cutoff, pca_components, weight, pre_epochs, epochs, lr, weight_decay, random_seed, mse_weight, bce_kld_weight, kl_weight, State_Net, use_gpu)\u001B[0m\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mann_data \u001B[38;5;241m=\u001B[39m read_10X_Visium(path\u001B[38;5;241m=\u001B[39mpath,section_id\u001B[38;5;241m=\u001B[39msection_id)\n\u001B[1;32m---> 48\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mann_data \u001B[38;5;241m=\u001B[39m \u001B[43mget_image_crop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mann_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43msection_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msection_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43mcnnType\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcnnType\u001B[49m\u001B[43m,\u001B[49m\u001B[43mpca_n_comps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpca_components\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mann_data \u001B[38;5;241m=\u001B[39m augment_adata_(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mann_data,activate\u001B[38;5;241m=\u001B[39mactivate,weight\u001B[38;5;241m=\u001B[39mweight)\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mann_data\u001B[38;5;241m.\u001B[39mX\n",
      "File \u001B[1;32mD:\\njy\\Project_AI_stRNA\\Code\\STMVGAE\\his_feat.py:215\u001B[0m, in \u001B[0;36mget_image_crop\u001B[1;34m(ann_data, section_id, cnnType, pca_n_comps)\u001B[0m\n\u001B[0;32m    213\u001B[0m save_path_image_crop\u001B[38;5;241m.\u001B[39mmkdir(parents\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    214\u001B[0m ann_data \u001B[38;5;241m=\u001B[39m image_crop(ann_data, save_path\u001B[38;5;241m=\u001B[39msave_path_image_crop)\n\u001B[1;32m--> 215\u001B[0m ann_data \u001B[38;5;241m=\u001B[39m \u001B[43mimage_feature\u001B[49m\u001B[43m(\u001B[49m\u001B[43mann_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpca_components\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpca_n_comps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcnnType\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcnnType\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_image_feat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ann_data\n",
      "File \u001B[1;32mD:\\njy\\Project_AI_stRNA\\Code\\STMVGAE\\his_feat.py:141\u001B[0m, in \u001B[0;36mimage_feature.extract_image_feat\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    139\u001B[0m tensor \u001B[38;5;241m=\u001B[39m tensor\u001B[38;5;241m.\u001B[39mresize_(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m224\u001B[39m,\u001B[38;5;241m224\u001B[39m) \u001B[38;5;66;03m#重构维度\u001B[39;00m\n\u001B[0;32m    140\u001B[0m tensor \u001B[38;5;241m=\u001B[39m tensor\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m--> 141\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mVariable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#放到cnn中提取特征\u001B[39;00m\n\u001B[0;32m    142\u001B[0m result_npy \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mravel()\n\u001B[0;32m    143\u001B[0m feat_df[spot] \u001B[38;5;241m=\u001B[39m result_npy\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\geo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\geo\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001B[0m, in \u001B[0;36mResNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 285\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\geo\\lib\\site-packages\\torchvision\\models\\resnet.py:268\u001B[0m, in \u001B[0;36mResNet._forward_impl\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_forward_impl\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    267\u001B[0m     \u001B[38;5;66;03m# See note [TorchScript super()]\u001B[39;00m\n\u001B[1;32m--> 268\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    269\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn1(x)\n\u001B[0;32m    270\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(x)\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\geo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\geo\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\geo\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    457\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    458\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "distType_list = ['Radius_balltree','KNN_balltree'] #distType_list\n",
    "\n",
    "for distType in distType_list:\n",
    "    DLPFC_dir = \"data/DLPFC/\"  #your path\n",
    "    section_id = \"151672\"  #DLPFC slice\n",
    "    k = 5  #the number of spatial domain \n",
    "    ann_data = sc.read_visium(os.path.join(DLPFC_dir, section_id),\n",
    "                              count_file=section_id + '_filtered_feature_bc_matrix.h5')\n",
    "    \n",
    "    \n",
    "    train = train_model(path=DLPFC_dir,input_dim=3000,section_id=section_id,cnnType='ResNet50',activate='Relu',weight=0.2,distType=distType,rad_cutoff=250,k_cutoff=12)\n",
    "    ann_data = train.fit(clusterType='Mclust',cluster_n=25)\n",
    "\n",
    "    # load groud truth\n",
    "    ann_df = pd.read_csv(os.path.join(DLPFC_dir, section_id, section_id + \"_truth.txt\"),\n",
    "                         sep=\"\\t\", header=None, index_col=0)\n",
    "    ann_df.columns = [\"Manual annotation\"]\n",
    "    ann_data.obs.loc[:, \"Manual annotation\"] = ann_df.loc[ann_data.obs_names, 'Manual annotation']\n",
    "    ann_data.var_names_make_unique()\n",
    "    print(ann_data)\n",
    "    \n",
    "    from scipy.spatial import distance\n",
    "    '''\n",
    "    \n",
    "    adata = KMeans_P(ann_data, n_clusters=k,use_rep='z')\n",
    "    indices = np.logical_not(ann_data.obs[\"Manual annotation\"].isna())\n",
    "    ground_truth = ann_data.obs[\"Manual annotation\"].dropna()\n",
    "    kmeans_ari = adjusted_rand_score(ann_data.obs['kmeans'][indices], ground_truth[indices])\n",
    "    print(\"ARI: {:.4f}\".format(kmeans_ari))\n",
    "    \n",
    "    adj_2d = distance.cdist(adata.obsm['spatial'], adata.obsm['spatial'], 'euclidean')\n",
    "    refined_pred = refine(sample_id=ann_data.obs.index.tolist(),\n",
    "                          pred=ann_data.obs[\"kmeans\"].tolist(), dis=adj_2d, shape=\"hexagon\")\n",
    "    ann_data.obs[\"kmeans_refine\"] = refined_pred\n",
    "    mclust_refine_ari = adjusted_rand_score(ann_data.obs['kmeans_refine'][indices], ground_truth[indices])\n",
    "    print(\"mclust_refine ari is: {:.4f}\".format(mclust_refine_ari))\n",
    "    mclust_refine_nmi = normalized_mutual_info_score(ann_data.obs['kmeans_refine'][indices], ground_truth[indices])\n",
    "    print(\"mclust_refine nmi is: {:.4f}\".format(mclust_refine_nmi))\n",
    "    mclust_refine_hs = homogeneity_score(ann_data.obs['kmeans_refine'][indices], ground_truth[indices])\n",
    "    print(\"mclust_refine hs is: {:.4f}\".format(mclust_refine_hs))\n",
    "    mclust_refine_purity = purity_score(ann_data.obs['kmeans_refine'][indices], ground_truth[indices])\n",
    "    print(\"mclust_refine purity is: {:.4f}\".format(mclust_refine_purity))\n",
    "    '''\n",
    "    #mclust clustering\n",
    "    adata = mclust_R(ann_data, used_obsm='z', num_cluster=k) \n",
    "    indices = np.logical_not(ann_data.obs[\"Manual annotation\"].isna())\n",
    "    ground_truth = ann_data.obs[\"Manual annotation\"].dropna()\n",
    "    mclust_ari = adjusted_rand_score(ann_data.obs['mclust'][indices], ground_truth[indices])\n",
    "    print(\"mclust ari is: {:.4f}\".format(mclust_ari))\n",
    "    mclust_nmi = normalized_mutual_info_score(ann_data.obs['mclust'][indices], ground_truth[indices])\n",
    "    print(\"mclust nmi is: {:.4f}\".format(mclust_nmi))\n",
    "    mclust_hs = homogeneity_score(ann_data.obs['mclust'][indices], ground_truth[indices])\n",
    "    print(\"mclust hs is: {:.4f}\".format(mclust_hs))\n",
    "    mclust_purity = purity_score(ann_data.obs['mclust'][indices], ground_truth[indices])\n",
    "    print(\"mclust purity is: {:.4f}\".format(mclust_purity))\n",
    "    \n",
    "    \n",
    "    #refine the clustring result\n",
    "    adj_2d = distance.cdist(adata.obsm['spatial'], adata.obsm['spatial'], 'euclidean')\n",
    "    refined_pred = refine(sample_id=ann_data.obs.index.tolist(),\n",
    "                          pred=ann_data.obs[\"mclust\"].tolist(), dis=adj_2d, shape=\"hexagon\")\n",
    "    ann_data.obs[\"mclust_refine\"] = refined_pred\n",
    "    mclust_refine_ari = adjusted_rand_score(ann_data.obs['mclust_refine'][indices], ground_truth[indices])\n",
    "    print(\"mclust_refine ari is: {:.4f}\".format(mclust_refine_ari))\n",
    "    mclust_refine_nmi = normalized_mutual_info_score(ann_data.obs['mclust_refine'][indices], ground_truth[indices])\n",
    "    print(\"mclust_refine nmi is: {:.4f}\".format(mclust_refine_nmi))\n",
    "    mclust_refine_hs = homogeneity_score(ann_data.obs['mclust_refine'][indices], ground_truth[indices])\n",
    "    print(\"mclust_refine hs is: {:.4f}\".format(mclust_refine_hs))\n",
    "    mclust_refine_purity = purity_score(ann_data.obs['mclust_refine'][indices], ground_truth[indices])\n",
    "    print(\"mclust_refine purity is: {:.4f}\".format(mclust_refine_purity))\n",
    "    \n",
    "    #save the result\n",
    "    file = adata.obs['mclust_refine']\n",
    "    np.save(os.path.join(distType,section_id,section_id+'_pred.npy'),file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T08:36:26.265337500Z",
     "start_time": "2024-04-17T08:36:17.877779Z"
    }
   },
   "id": "e529fcfb2dd08ef3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Consensus Clustering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e74571fa463f2b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "from typing import List\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "\n",
    "def labels_connectivity_mat(labels: np.ndarray):\n",
    "    _labels = labels - np.min(labels)\n",
    "    n_classes = np.unique(_labels)\n",
    "    mat = np.zeros([labels.size, labels.size])\n",
    "    for i in n_classes:\n",
    "        indices = np.squeeze(np.where(_labels == i))  #将属于各个类的标签提取出来\n",
    "        row_indices, col_indices = zip(*itertools.product(indices, indices))\n",
    "        mat[row_indices, col_indices] = 1\n",
    "    return mat\n",
    "\n",
    "\n",
    "def consensus_matrix(labels_list: List[np.ndarray]):\n",
    "    mat = 0\n",
    "    for labels in labels_list:\n",
    "        mat += labels_connectivity_mat(labels)\n",
    "    return mat / float(len(labels_list))\n",
    "\n",
    "\n",
    "def plot_consensus_map(cmat, method=\"average\", return_linkage=True, **kwargs):\n",
    "    row_linkage = hierarchy.linkage(distance.pdist(cmat), method=method)\n",
    "    col_linkage = hierarchy.linkage(distance.pdist(cmat.T), method=method)\n",
    "    figure = sns.clustermap(cmat, row_linkage=row_linkage, col_linkage=col_linkage, **kwargs)\n",
    "    if return_linkage:\n",
    "        return row_linkage, col_linkage, figure\n",
    "    else:\n",
    "        return figure\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T08:36:26.270324100Z",
     "start_time": "2024-04-17T08:36:26.266332300Z"
    }
   },
   "id": "fb56defe55ca4e0f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_dir = 'consensus-clustering/151672' #save dir of consensus clustring result \n",
    "num_cluster = 5 \n",
    "\n",
    "label_files1 = np.load(os.path.join('Radius_balltree',section_id,section_id+'_pred.npy'))\n",
    "label_files2 = np.load(os.path.join('KNN_balltree',section_id,section_id+'_pred.npy'))\n",
    "labels_list = list([label_files1,label_files2])\n",
    "\n",
    "cons_mat = consensus_matrix(labels_list)\n",
    "row_linkage, _, _ = plot_consensus_map(cons_mat, return_linkage=True)  # 获取层次聚类结果和热度图\n",
    "#figure.savefig(os.path.join(save_dir, \"consensus_clustering.png\"), dpi=300)  # 保存图片\n",
    "consensus_labels = hierarchy.cut_tree(row_linkage, num_cluster).squeeze()  # 得到y*\n",
    "np.save(os.path.join(save_dir, \"consensus_labels\"), consensus_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-17T08:36:26.267329800Z"
    }
   },
   "id": "e50e6eecbd892d79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DLPFC_dir = \"data/DLPFC/\"\n",
    "section_id = \"151672\"\n",
    "ann_data = sc.read_visium(os.path.join(DLPFC_dir, section_id),\n",
    "                          count_file=section_id + '_filtered_feature_bc_matrix.h5')\n",
    "# load groud truth\n",
    "ann_df = pd.read_csv(os.path.join(DLPFC_dir, section_id, section_id + \"_truth.txt\"),\n",
    "                     sep=\"\\t\", header=None, index_col=0)\n",
    "ann_df.columns = [\"Manual annotation\"]\n",
    "ann_data.obs.loc[:, \"Manual annotation\"] = ann_df.loc[ann_data.obs_names, 'Manual annotation']\n",
    "ann_data.var_names_make_unique()\n",
    "print(adata)\n",
    " \n",
    "#consensus clustering result\n",
    "pred = np.load('consensus-clustering/151672/consensus_labels.npy')\n",
    "ann_data.obs['consensus_label'] = pred\n",
    "indices = np.logical_not(ann_data.obs[\"Manual annotation\"].isna())\n",
    "ground_truth = ann_data.obs[\"Manual annotation\"].dropna()\n",
    "ari = adjusted_rand_score(pred[indices], ground_truth[indices])\n",
    "print(\"ari is: {:.4f}\".format(ari))\n",
    "nmi = normalized_mutual_info_score(pred[indices], ground_truth[indices])\n",
    "print(\"nmi is: {:.4f}\".format(nmi))\n",
    "hs = homogeneity_score(pred[indices], ground_truth[indices])\n",
    "print(\"hs is: {:.4f}\".format(hs))\n",
    "purity = purity_score(pred[indices], ground_truth[indices])\n",
    "print(\"purity is: {:.4f}\".format(purity))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-17T08:36:26.270324100Z"
    }
   },
   "id": "ef363528ab43e580"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#SVGs Identification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ccaffb95d93b3b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import SpaGCN as spg\n",
    "import matplotlib.colors as clr\n",
    "\n",
    "raw = sc.read_visium(os.path.join(DLPFC_dir, section_id),\n",
    "                          count_file=section_id + '_filtered_feature_bc_matrix.h5')\n",
    "raw.var_names_make_unique()\n",
    "raw.obs[\"pred\"]=ann_data.obs[\"consensus_label\"].astype('category')\n",
    "raw.obs[\"x_array\"]=raw.obs[\"array_row\"]\n",
    "raw.obs[\"y_array\"]=raw.obs[\"array_col\"]\n",
    "raw.obs[\"x_pixel\"] = raw.obsm['spatial'][:,0]\n",
    "raw.obs[\"y_pixel\"] = raw.obsm['spatial'][:,1]\n",
    "x_array = raw.obs[\"x_array\"].tolist()\n",
    "y_array = raw.obs[\"y_array\"].tolist()\n",
    "x_pixel = raw.obs[\"x_pixel\"].tolist()\n",
    "y_pixel = raw.obs[\"y_pixel\"].tolist()\n",
    "raw.X = (raw.X.A if issparse(raw.X) else raw.X)\n",
    "raw.raw = raw\n",
    "sc.pp.log1p(raw)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-17T08:36:26.271321300Z"
    }
   },
   "id": "b9e64e3916fedda0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Use domain 0 as an example\n",
    "target=1\n",
    "#Set filtering criterials\n",
    "min_in_group_fraction=0.8\n",
    "min_in_out_group_ratio=1\n",
    "min_fold_change=1\n",
    "#Search radius such that each spot in the target domain has approximately 10 neighbors on average\n",
    "adj_2d=spg.calculate_adj_matrix(x=x_array, y=y_array, histology=False)\n",
    "start, end= np.quantile(adj_2d[adj_2d!=0],q=0.001), np.quantile(adj_2d[adj_2d!=0],q=0.1)\n",
    "r=spg.search_radius(target_cluster=target, cell_id=ann_data.obs.index.tolist(), x=x_array, y=y_array, pred=ann_data.obs[\"consensus_label\"].tolist(), start=start, end=end, num_min=10, num_max=200,  max_run=100)\n",
    "#Detect neighboring domains\n",
    "nbr_domians=spg.find_neighbor_clusters(target_cluster=target,\n",
    "                                   cell_id=raw.obs.index.tolist(), \n",
    "                                   x=raw.obs[\"x_array\"].tolist(), \n",
    "                                   y=raw.obs[\"y_array\"].tolist(), \n",
    "                                   pred=raw.obs[\"pred\"].tolist(),\n",
    "                                   radius=r,\n",
    "                                   ratio=1/2)\n",
    "nbr_domians=nbr_domians[0:3]\n",
    "de_genes_info=spg.rank_genes_groups(input_adata=raw,\n",
    "                                target_cluster=target,\n",
    "                                nbr_list=nbr_domians, \n",
    "                                label_col=\"pred\", \n",
    "                                adj_nbr=True, \n",
    "                                log=True)\n",
    "#Filter genes\n",
    "de_genes_info=de_genes_info[(de_genes_info[\"pvals_adj\"]<0.05)]\n",
    "filtered_info=de_genes_info\n",
    "filtered_info=filtered_info[(filtered_info[\"pvals_adj\"]<0.05) &\n",
    "                            (filtered_info[\"in_out_group_ratio\"]>min_in_out_group_ratio) &\n",
    "                            (filtered_info[\"in_group_fraction\"]>min_in_group_fraction) &\n",
    "                            (filtered_info[\"fold_change\"]>min_fold_change)]\n",
    "filtered_info=filtered_info.sort_values(by=\"in_group_fraction\", ascending=False)\n",
    "filtered_info[\"target_dmain\"]=target\n",
    "filtered_info[\"neighbors\"]=str(nbr_domians)\n",
    "print(\"SVGs for domain \", str(target),\":\", filtered_info[\"genes\"].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-17T08:36:26.272315600Z"
    }
   },
   "id": "b733f3424794b2a4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gene_list = ['ENC1']\n",
    "\n",
    "color_self = clr.LinearSegmentedColormap.from_list('pink_green', ['#3AB370',\"#EAE7CC\",\"#FD1593\"], N=256)\n",
    "for g in gene_list:\n",
    "#for g in filtered_info[\"genes\"].tolist():\n",
    "    raw.obs[\"exp\"]=raw.X[:,raw.var.index==g]\n",
    "    sc.pl.spatial(raw, img_key=\"hires\",\n",
    "              color=\"exp\",\n",
    "              title=g,\n",
    "              color_map=color_self)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-17T08:36:26.273313100Z"
    }
   },
   "id": "e76c4fd83db5e5ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target=1\n",
    "meta_name, meta_exp=spg.find_meta_gene(input_adata=raw,\n",
    "                    pred=raw.obs[\"pred\"].tolist(),\n",
    "                    target_domain=target,\n",
    "                    start_gene=\"ENC1\",\n",
    "                    mean_diff=0,\n",
    "                    early_stop=True,\n",
    "                    max_iter=3,\n",
    "                    use_raw=False)\n",
    "\n",
    "raw.obs[\"meta\"]=meta_exp\n",
    "\n",
    "raw.obs[\"exp\"]=raw.obs[\"meta\"]\n",
    "sc.pl.spatial(raw, img_key=\"hires\",\n",
    "              color=\"exp\",\n",
    "              title='meta',\n",
    "              color_map=color_self)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-17T08:36:26.274310100Z"
    }
   },
   "id": "c26b407f00afd083"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T08:36:26.277302100Z",
     "start_time": "2024-04-17T08:36:26.275307300Z"
    }
   },
   "id": "d0c0add7014c7709"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
